{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3mgm5pieFOY"
      },
      "source": [
        "## PW on graphcut optimization (binary case)\n",
        "This session is divided into 3 parts:\n",
        "\n",
        "\n",
        "* a part on Bayesian classification\n",
        "* a part on object/background segmentation of a colour image with a CRF (conditional random filed)\n",
        "* a part on the iterative segmentation of a textured image\n",
        "\n",
        "We will use the PyMaxflow library for the calculation of the graphcut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-fqZE_aeALW",
        "outputId": "867a7db3-7758-4b7c-b041-ef2d46e6f17e"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"TP_graphcut_part_1.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/10oEfwo5gV-LTy9YZIzd4IqwuiF4ROaCW\n",
        "\n",
        "## PW on graphcut optimization (binary case)\n",
        "This session is divided into 3 parts:\n",
        "* a part on Bayesian classification\n",
        "* a part on object/background segmentation of a colour image with a CRF (conditional random filed)\n",
        "* a part on the iterative segmentation of a textured image\n",
        "\n",
        "We will use the PyMaxflow library for the calculation of the graphcut.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import imageio\n",
        "import scipy.signal\n",
        "import scipy.ndimage\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from skimage.morphology import binary_dilation, disk\n",
        "from skimage import color\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "try:\n",
        "    import maxflow  # if not installed, install Maxflow\n",
        "except:\n",
        "    !pip install PyMaxflow # For Google Collab\n",
        "    import maxflow\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.plotting import show as showbokeh\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "def affiche_pour_colab(im, MINI=None, MAXI=None, titre=\"\"):  # special colab, don't look\n",
        "    \"\"\"\n",
        "    Display an image in a Jupyter notebook using Bokeh.\n",
        "\n",
        "    Args:\n",
        "        im (ndarray): The input image.\n",
        "        MINI (float): The minimum value for normalization (optional).\n",
        "        MAXI (float): The maximum value for normalization (optional).\n",
        "        titre (string): The title of the plot (optional).\n",
        "    \"\"\"\n",
        "\n",
        "    p = figure(\n",
        "        tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")],\n",
        "        y_range=[im.shape[0], 0],\n",
        "        x_range=[0, im.shape[1]],\n",
        "        title=titre,\n",
        "    )\n",
        "    # p.x_range.range_padding = p.y_range.range_padding = 0\n",
        "    # must give a vector of images\n",
        "    p.image(\n",
        "        image=[np.flipud(im)],\n",
        "        x=0,\n",
        "        y=im.shape[0],\n",
        "        dw=im.shape[1],\n",
        "        dh=im.shape[0],\n",
        "        palette=\"Greys9\",\n",
        "        level=\"image\",\n",
        "    )\n",
        "    p.xgrid.visible = False\n",
        "    p.ygrid.visible = False\n",
        "    showbokeh(p)\n",
        "\n",
        "def affiche(im, MINI=0.0, MAXI=None, titre=\"\", printname=False):\n",
        "    \"\"\"\n",
        "    Display an image in a Jupyter notebook using Bokeh.\n",
        "\n",
        "    Args:\n",
        "        im (ndarray): The input image.\n",
        "        MINI (float): The minimum value for normalization (optional).\n",
        "        MAXI (float): The maximum value for normalization (optional).\n",
        "        titre (string): The title of the plot (optional).\n",
        "        printname (boolean): Whether to print the name (optional).\n",
        "    \"\"\"\n",
        "    affiche_pour_colab(\n",
        "        im, MINI=MINI, MAXI=MAXI, titre=titre\n",
        "    )  # under google colab many options disappear\n",
        "\n",
        "def display_segmentation_borders(image, bin):\n",
        "    \"\"\"\n",
        "    Display the segmentation borders on the image.\n",
        "\n",
        "    Args:\n",
        "        image (ndarray): The input image.\n",
        "        bin (ndarray): The binary segmentation mask.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The image with segmentation borders highlighted.\n",
        "    \"\"\"\n",
        "    contour = binary_dilation(bin, disk(15)) ^ bin\n",
        "\n",
        "    imagergb = np.copy(image)\n",
        "    imagergb[contour == 1, 0] = 255\n",
        "    imagergb[contour == 1, 1] = 0\n",
        "    imagergb[contour == 1, 2] = 0\n",
        "\n",
        "    return imagergb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nndFrzQkeALh"
      },
      "source": [
        "## Binary classification of a noisy image\n",
        "\n",
        "You have a binary image *IoriginaleBW.png* (binary image of the two classes) and its observed version with a certain distribution of grey levels for each class *Iobservee.png*. The objective is to perform a two-class classification of this observed image (see PW1 and PW2).\n",
        "\n",
        "### Analysis of the distributions of the 2 classes of the image}\n",
        "\n",
        "\n",
        "Q1: What are the distributions of the two classes of the image ($P(Y_s|X_s=0)$ (black class) and $P(Y_s|X_s=0)$ (white class))?\n",
        "\n",
        "Q2: Give the means and variances of the two classes.\n",
        "\n",
        "*The distributions and the means and variances found in the previous sessions will be used without justification*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6Re5qCeALh"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A1: Both classes follow a normal distribution.\n",
        "\n",
        "A2: Class 0 : mean = 97.4, variance = 22.3  \n",
        "    Class 1 : mean = 163.9, variance = 22.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjYI0DBieALj"
      },
      "source": [
        "## 1.1: Graphcut optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JNLl31geALk"
      },
      "source": [
        "Q3: How many nodes does the graph have that is constructed for the search for the minimum capacity cut with only two neighbouring pixels? What do they correspond to? What do the data attachment terms in this graph correspond to and what values do they have for two observed pixels of values $y_s$ and $y_t$? What does the regularisation term correspond to?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ7V-ZL8eALl"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A3: This graph has 4 nodes. Two of them correspond to the pixels. The others correspond to the labels (one for each class). The attachment terms in this graph are the edges between the label nodes and the pixel nodes. The value of each of these links is equal to the negative log-likelihood of the value of the pixel node with respect to the corresponding classes distribution.  \n",
        "With $\\mu_i$ the mean of the pixels' distributions, the edges' weights are $(y_s-\\mu_i)Â²$\n",
        "The regularisation terms are equal to $\\beta$ and correspond to the edges between the pixel nodes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_eBP8w7eALl"
      },
      "source": [
        "Q4: Complete the python code cell where it says \"#TO BE COMPLETED EX1\" with the data attachment and regularization terms as indicated. Run the minimum cut algorithm and view the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcNyoI-3kP_4"
      },
      "source": [
        "## 1.2 Searching for the optimal $\\beta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFgB73kLeALn"
      },
      "source": [
        "\n",
        "\n",
        "Q5: By completing the program frame provided below, find the optimal $\\beta$ value $\\beta_{opt}$ using the \"true image\" $x$ corresponding to IoriginaleBW.png. You can plot the error values between $x$ and the estimated $\\hat{x}$ to find $\\beta_{opt}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEv5jM1KeALo"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A5: $\\beta_{opt}$ = 1890"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9VAuDBJgrLx"
      },
      "source": [
        "Q6: What are the advantages of this optimization approach compared to ICM? Compared to simulated annealing? In theory, do we obtain the same result with both methods (simulated annealing and graphcut)? Under what conditions? What is the advantage of simulated annealing in the general case?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uqBSHTkgw6P"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A6: The advantages of this optimization approach compared to ICM are that the solution found by the graph cut is a global minimum whereas ICM finds a local minimum. Graph cut's solution is thus better. Also, we find the solution is found faster with the graph cut method. The ICM method also requires an initialisation while graph cut doesn't.\n",
        "\n",
        "\n",
        "\n",
        "The main advantage of graph cut over simulated annealing is that it finds the solution much faster. Like ICM, simulated also requires an initialisation that graph cut doesn't.\n",
        "\n",
        "\n",
        "\n",
        "In theory, we obtain the same result with both methods under the condition that we decrease the temperature slowly enough.\n",
        "\n",
        "\n",
        "In practice, the simulated annealing always gives the global minimum no matter the model while graph cut finds the global minimum considering the model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9SgH432eALp"
      },
      "source": [
        "\n",
        "Q7: How can you explain that the error rate with the true image can be lower with the simulated annealing result or the ICM than with the graph-cut optimisation?\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzFxm1useALq"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A7: We don't want to choose the global minimum found by the graph cut because the latter doesn't model the problem perfectly whereas the solution found with simulated annealing is better in the sense that it's a stochastic approximation of the global minimum and is therefore more realistic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjgmIJCjjUPV"
      },
      "source": [
        "Q8: What are the advantages and disadvantages of the Ising model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQNFzj8Jjett"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A8: The Ising model is interesting because it only involves a close neighborhood of the pixels we are looking at. This is computationaly interesting. Also we often find in natural images that neighboring pixels have very similar colors or intensities.\n",
        "However the problem could be that thin structures that involve a line of pixels being correlated instead of the correlation of all the nearest neighbors can be easily ignored. For example, when looking at a vein pixel, the surrounding ones can be part of the background and the Ising model will push to make the vein pixel background. Another disadvantage of the Ising model is that it is too restrictive if we decide to apply it on grayscale images. In this case, this model is called Potts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "tRdTaqnheALq",
        "outputId": "2fdf9b2e-f035-47e7-a2fa-c2c49769f2dc"
      },
      "outputs": [],
      "source": [
        "# Loading images\n",
        "\n",
        "def open_image_from_url(url):\n",
        "    \"\"\"\n",
        "    Opens an image from the given URL and returns it as a NumPy array.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the image to be opened.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The image as a NumPy array.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    return np.array(img)\n",
        "\n",
        "# Observed image, noisy\n",
        "im_obs = (\n",
        "    open_image_from_url(\"https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee.png\")\n",
        "    * 255\n",
        ")\n",
        "\n",
        "# Binary reference image, to assess the quality of the segmentation\n",
        "im_orig = open_image_from_url(\n",
        "    \"https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/IoriginaleBW.png\"\n",
        ")\n",
        "\n",
        "affiche(im_obs, titre=\"Observed image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "d0YUOGyqeALq",
        "outputId": "920fc110-cb6d-47a9-a3bc-d024126dffcc"
      },
      "outputs": [],
      "source": [
        "#### to be completed\n",
        "# TO BE COMPLETED EX1\n",
        "beta = 1890  # beta value\n",
        "m0 = 97.4  # m0 and m1 values from the previous practical work\n",
        "m1 = 163.9\n",
        "\n",
        "## binary graph-cut\n",
        "\n",
        "# Create the graph.\n",
        "g = maxflow.Graph[float]()  # Graph instantiation\n",
        "\n",
        "# Add the nodes.\n",
        "# nodeids has the identifiers of the nodes in the grid.\n",
        "# It creates a set of nodes for all the pixels of the image\n",
        "nodeids = g.add_grid_nodes(im_obs.shape)\n",
        "\n",
        "# Add non-terminal edges with the same capacity.\n",
        "# The edge has the value beta for all adjacent pixels in 4-connexity\n",
        "g.add_grid_edges(nodeids, beta)\n",
        "\n",
        "# Add the terminal edges.\n",
        "# The second argument correspond to the set of edge values to the source\n",
        "# The third argument correspond to the set of edge values to the sink\n",
        "g.add_grid_tedges(nodeids, (im_obs - m0) ** 2, (im_obs - m1) ** 2)\n",
        "\n",
        "# Find the maximum flow.\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "# Get the labels of the nodes in the grid.\n",
        "# Output is 0 if the node is connected to the source, else output is 1\n",
        "sgm = g.get_grid_segments(nodeids)\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "affiche(im_bin, titre=\"Result for beta = \" + str(beta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "iWDVl5ceeALr",
        "outputId": "6db485d7-4a66-4245-adf7-334edfedbd7e"
      },
      "outputs": [],
      "source": [
        "# Compute the error image between im_bin and im_orig (the ideal solution) using np.abs and np.sum\n",
        "error = np.sum(im_bin != im_orig)\n",
        "\n",
        "# Visualize the differences between the original image and the solution\n",
        "plt.figure()\n",
        "plt.imshow(np.dstack((np.int_(im_orig), im_bin, im_bin)) * 255)\n",
        "plt.title(\"Result for beta = \" + str(beta) + \" and truth\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Number of misclassified pixels for beta = \", beta, \": \", int(error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD0sTgGoeALr"
      },
      "source": [
        "### Search for the best parameter $\\beta$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "Kf5x86KgeALs",
        "outputId": "2ca7f324-4e3b-4bed-a10c-60d09100a535"
      },
      "outputs": [],
      "source": [
        "im_obs = (\n",
        "    open_image_from_url(\"https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee.png\")\n",
        "    * 255\n",
        ")  # Observed image, noisy\n",
        "im_orig = open_image_from_url(\n",
        "    \"https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/IoriginaleBW.png\"\n",
        ")  # Binary reference image, to assess the quality of the segmentation\n",
        "\n",
        "# TO BE COMPLETED - choose a range of values and a step to study beta\n",
        "def find_beta(start, stop, step):\n",
        "    list_beta = []\n",
        "    list_errors = []\n",
        "    for beta in range(start, stop, step):\n",
        "        # TO BE COMPLETED\n",
        "        m0 = 97.4\n",
        "        m1 = 163.9\n",
        "\n",
        "        ## Binary graph cut\n",
        "\n",
        "        # Create the graph\n",
        "        g = maxflow.Graph[float]()  # graph instantiation\n",
        "\n",
        "        # Add the nodes. nodeids has the identifiers of the nodes in the grid.\n",
        "        nodeids = g.add_grid_nodes(im_obs.shape)\n",
        "        # Add non-terminal edges with the same capacity.\n",
        "        g.add_grid_edges(nodeids, beta)\n",
        "        # Add the terminal edges.\n",
        "        g.add_grid_tedges(nodeids, (im_obs - m0) ** 2, (im_obs - m1) ** 2)\n",
        "\n",
        "        # Find the maximum flow.\n",
        "        g.maxflow()\n",
        "\n",
        "        # Get the segments of the nodes in the grid.\n",
        "        sgm = g.get_grid_segments(nodeids)\n",
        "        # create the output image\n",
        "        im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "        # Compute the error\n",
        "        error = np.sum(im_bin != im_orig)\n",
        "        list_beta.append(beta)\n",
        "        list_errors.append(error)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(list_beta, list_errors)\n",
        "    plt.xlabel(\"beta\")\n",
        "    plt.ylabel(\"number of misclassified pixels\")\n",
        "    plt.show()\n",
        "\n",
        "    best_beta = list_beta[np.argmin(np.array(list_errors))]\n",
        "\n",
        "    print(\"Best beta value: \", best_beta)\n",
        "\n",
        "find_beta(1000, 3000, 100)\n",
        "find_beta(1700, 1950, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDJDhepieALs"
      },
      "source": [
        "## 2. Classification of a colour image\n",
        "\n",
        "The objective of this part is to carry out an extension of the method seen previously in the case of the treatment of a colour image *avions.png* in which one wants to separate the objects from the background.\n",
        "\n",
        "We will first use the same framework (Ising model) as before but with a three-dimensional data attachment (assuming convariance matrices equal to the identity). Then we will introduce a CRF (conditional random field) by weighting the regularisation term of the Ising model by the modulus of the gradient between two pixels of the observed image.  \n",
        "\n",
        "### 2.1 Binary classification\n",
        "From the program structure below, carry out the different steps necessary for this classification:\n",
        "1. Modelling of the background and object distributions (in 3 dimensions this time)\n",
        "1. Definition of the data attachment term\n",
        "1. Choice of a value for the regularisation parameter for the Ising model\n",
        "1. Finding the minimal cut to obtain the object/background classification.\n",
        "\n",
        "Q9: Comment on these steps and the results obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfXuLLE4eALs"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A9:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "rk1Nj14meALs",
        "outputId": "baae5927-b6a3-49ab-a40e-466fdf87c4ae"
      },
      "outputs": [],
      "source": [
        "# Loading and displaying the image\n",
        "im_obs = open_image_from_url(\n",
        "    \"https://www.dropbox.com/s/ylm0ut8ipu5oonb/avions.png?dl=1\"\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 15]\n",
        "plt.imshow(im_obs)\n",
        "plt.show()\n",
        "\n",
        "# Conversion of the image between 0 and 255\n",
        "im_obs = 255 * im_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPsAftnceALt"
      },
      "source": [
        "#### Determining the parameters of the classes\n",
        "\n",
        "\n",
        "Plane class: we can use the values of the rectangle [180:200,280:300].\n",
        "\n",
        "example np.mean(image[180:200,280:300,1]) returns the average of the selected area for channel 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16tOLr7ZeALt",
        "outputId": "2de13af3-0786-4b5b-98b0-e2f7a878ac8b"
      },
      "outputs": [],
      "source": [
        "# Mean of the plane class - 3D vector\n",
        "m_planes = np.mean(im_obs[180:200, 280:300], axis=(0, 1))\n",
        "\n",
        "# Mean of the sky class\n",
        "# You can use values in the following square [0:100,150:300]\n",
        "m_sky = np.mean(im_obs[0:100, 150:300], axis=(0, 1))\n",
        "\n",
        "# Check that the obtained values are coherent\n",
        "print(\"For the sky, [R,G,B] = \", m_sky)\n",
        "print(\"For the planes, [R,G,B] = \", m_planes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uF7ZH7EveALu",
        "outputId": "20d7da35-d720-4795-cf18-7fb507b19d4d"
      },
      "outputs": [],
      "source": [
        "# Choose a beta value\n",
        "beta = 20\n",
        "\n",
        "# TO BE COMPLETED\n",
        "## Binary graph-cut\n",
        "# use the previous program to create the graph and compute the cut\n",
        "# be careful of computing the terminal weights using the 3D values\n",
        "# you can compute 2 distance images with, in each pixel, the quadratic distance to the mean value\n",
        "# of each class\n",
        "m0 = m_planes  # m0 and m1 values from the previous practical work\n",
        "m1 = m_sky\n",
        "\n",
        "## Binary graph-cut\n",
        "\n",
        "# Create the graph.\n",
        "g = maxflow.Graph[float]()  # Graph instantiation\n",
        "\n",
        "# Add the nodes.\n",
        "# nodeids has the identifiers of the nodes in the grid.\n",
        "# It creates a set of nodes for all the pixels of the image\n",
        "nodeids = g.add_grid_nodes(im_obs.shape)\n",
        "\n",
        "# Add non-terminal edges with the same capacity.\n",
        "# the edge has the value beta for all adjacent pixels in 4-connexity\n",
        "g.add_grid_edges(nodeids, beta)\n",
        "\n",
        "# Add the terminal edges.\n",
        "# The second argument correspond to the set of edge values to the source\n",
        "# The third argument correspond to the set of edge values to the sink\n",
        "g.add_grid_tedges(nodeids, (im_obs - m0) ** 2, (im_obs - m1) ** 2)\n",
        "\n",
        "# Find the maximum flow.\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "# Get the labels of the nodes in the grid.\n",
        "# output is 0 if the node is connected to the source, else output is 1\n",
        "sgm = g.get_grid_segments(nodeids)\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "plt.imshow(255 * im_bin)\n",
        "plt.show()\n",
        "\n",
        "print(\"Class is chosen by majority voting:\")\n",
        "im_bin = np.sum(im_bin, axis=2) // 2\n",
        "plt.imshow(255 * im_bin, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwxEgcMyeALu"
      },
      "source": [
        "### 2.2 Use of a CRF (Conditional Random Field) model\n",
        "\n",
        "We will try here to adapt the model used previously to favour transitions where they are compatible with the gradient. To do this, we will replace the constant $\\beta$ for the whole image by a \"beta_field\" which depends on the norm of the gradient.\n",
        "\n",
        "Q10: Calculate and display the modulus of the gradient of the aircraft image after it has been grayscaled and convolved by a Gaussian kernel of standard deviation 1. Why use the \"boundary='symm'\" option when convolving through the Sobel filter? Try it without doing the Gaussian filtering. What is the point?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT3EdCcMuH5E"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A10: In order to keep our image size, we need to add pixels around the image before convolving. To make sure these pixels make sense, we use the 'symm option because there only is sky in the borders of our image. This element is plain and can be mirrored without altering its sense.\n",
        "\n",
        "Without Gaussian filtering, we note that the planes are almost undistinguishable against the noise. The filter reduces the noise and it allows the gradient to put the emphasis on the planes' contours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ROpDhuB-eALv",
        "outputId": "65ddc9d1-1440-4245-81a2-f1793e48ed01"
      },
      "outputs": [],
      "source": [
        "def gradient(image):\n",
        "    \"\"\"\n",
        "    Calculate the gradient of an image using the Sobel operator.\n",
        "\n",
        "    Args:\n",
        "        image (ndarray): The input image.\n",
        "\n",
        "    Returns:\n",
        "        tuple of ndarray: The gradient of the image in the x and y directions.\n",
        "    \"\"\"\n",
        "    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float)\n",
        "    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float)\n",
        "\n",
        "    # to be completed\n",
        "    # use mode = 'same' and boundary='symm' in scipy.signal.convolve2d\n",
        "    derivative_x = scipy.signal.convolve2d(image, sobel_x, mode=\"same\", boundary=\"symm\")\n",
        "    derivative_y = scipy.signal.convolve2d(image, sobel_y, mode=\"same\", boundary=\"symm\")\n",
        "    return [derivative_x, derivative_y]\n",
        "\n",
        "plane_nb = color.rgb2gray(im_obs)\n",
        "plane_x, plane_y = gradient(plane_nb)\n",
        "\n",
        "# Calculation of the gradient modulus\n",
        "grad_av = np.sqrt(np.square(plane_x) + np.square(plane_y))\n",
        "plt.figure()\n",
        "plt.title(\"Gradient without Gaussian filtering\", fontsize=20)\n",
        "plt.imshow(grad_av)\n",
        "plt.show()\n",
        "\n",
        "plane_nb = scipy.ndimage.gaussian_filter(color.rgb2gray(im_obs), 0.5)\n",
        "plane_x, plane_y = gradient(plane_nb)\n",
        "\n",
        "# Calculation of the gradient modulus\n",
        "grad_av = np.sqrt(np.square(plane_x) + np.square(plane_y))\n",
        "plt.figure()\n",
        "plt.title(\"Gradient with Gaussian filtering\", fontsize=20)\n",
        "plt.imshow(grad_av)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnT3Y0zOt_lN"
      },
      "source": [
        "\n",
        "Complete the code for segmentation by CRF. We will choose $beta\\_field=\\beta_2\\cdot\\exp(-grad\\_av/h)$ We can use $h=300$ and $\\beta_2=20000$. Also replace the constant beta by the field \"beta_field\" during the \"g.add_grid_edges\" step.\n",
        "\n",
        "Q11: Compare the results with and without the contour term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm01udUIxIHt"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A11: beta_field is used to guide the segmentation of the planes. When it is used, the borders are more regular. If the parameters are not set correctly, we find that the segmentations are too simple as we can see in the following images. When lowering the standard deviation of the Gaussian filter, we find more details but at the cost of bigger noise on the planes' contours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "imKywIsReALw",
        "outputId": "9967c4a5-4c63-4a33-c79c-54c75832a12b"
      },
      "outputs": [],
      "source": [
        "# Calculation of beta_field\n",
        "# This field will set the value for the 4-neighbours\n",
        "h = 300\n",
        "beta2 = 200\n",
        "beta_field = beta2 * np.exp(-grad_av / h)\n",
        "\n",
        "beta_field = np.repeat(\n",
        "    np.reshape(beta_field, (beta_field.shape[0], beta_field.shape[1], 1)), 3, axis=2\n",
        ")\n",
        "\n",
        "## Binary graph cut\n",
        "# Complete by taking your previous code and replacing\n",
        "# Beta by beta_field in the line g.add_grid_edges\n",
        "\n",
        "# m0 and m1 values from the previous practical work\n",
        "m0 = m_planes\n",
        "m1 = m_sky\n",
        "\n",
        "## Binary graph-cut\n",
        "\n",
        "# Create the graph.\n",
        "g = maxflow.Graph[float]()  # Graph instantiation\n",
        "\n",
        "# Add the nodes.\n",
        "# nodeids has the identifiers of the nodes in the grid.\n",
        "# It creates a set of nodes for all the pixels of the image\n",
        "nodeids = g.add_grid_nodes(im_obs.shape)\n",
        "\n",
        "# Add non-terminal edges with the same capacity.\n",
        "# The edge has the value beta for all adjacent pixels in 4-connexity\n",
        "g.add_grid_edges(nodeids, beta_field)\n",
        "\n",
        "# Add the terminal edges.\n",
        "# The second argument correspond to the set of edge values to the source\n",
        "# The third argument correspond to the set of edge values to the sink\n",
        "g.add_grid_tedges(nodeids, (im_obs - m0) ** 2, (im_obs - m1) ** 2)\n",
        "\n",
        "# Find the maximum flow.\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "\n",
        "# Get the segments of the nodes in the grid.\n",
        "sgm = g.get_grid_segments(\n",
        "    nodeids\n",
        ")  # Returns 1 if the pixel is on the drain side after calculating the min cut, 0 if it is on the source side\n",
        "\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "# affiche(im_bin, titre=\"Result for the CRF model\")\n",
        "plt.imshow(255 * im_bin)\n",
        "plt.show()\n",
        "\n",
        "print(\"Class is chosen by majority voting:\")\n",
        "im_bin = np.sum(im_bin, axis=2) // 2\n",
        "plt.imshow(255 * im_bin, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ezFoD6eALw"
      },
      "source": [
        "## 3. Iterative Segmentation with Gaussian Mixture\n",
        "\n",
        "Q12: Display the \"zebra\" image below. Is it possible to segment the zebra with the method used to segment the planes?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9E-e1IyydI-"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A12: We can't use the same algorithm because the zebra's fur is made of two very contrasted colors that will be segmented from one another. The intensity of the green of the grass around the animal falls between the intensities of the black and white of the stripes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MS9FTw3aeALw",
        "outputId": "108fb2ca-2684-40e2-e82a-03ec141b4898",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "### Loading a new image\n",
        "I_zebra = imageio.imread(\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/6/60/Equus_quagga.jpg\"\n",
        ")\n",
        "I_zebra = I_zebra[200:, :, :]\n",
        "rect_zebra = I_zebra[700:1100, 1000:2100]\n",
        "rect_background = I_zebra[:, 0:600]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(I_zebra)\n",
        "plt.title(\"I_zebra\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(rect_zebra)\n",
        "plt.title(\"rect_zebra\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(rect_background)\n",
        "plt.title(\"rect_background\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HGzR7tSeALx"
      },
      "source": [
        "Q13: Calculate the covariance matrix for the rect_zebra and the rect_background. Display the values and comment on the result. What do the diagonal values correspond to?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtKlw5ehRHzw"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A13: The diagonal values correspond to each color's variance. We find that the zebra's rectangle has very high variances which make sense since it is made of black and white, which are opposite intensities, in similar quantities. As for the background rectangle, the variances are pretty low which is explained by the fact that the patch is pretty homogeneous and fully green."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRsXhxJGeALx",
        "outputId": "22abc364-504f-4e3c-9dca-dae81f457665"
      },
      "outputs": [],
      "source": [
        "V_tulip = np.vstack([I_zebra[:, :, i].flatten() for i in range(3)])\n",
        "\n",
        "M_cov = np.cov(np.vstack([I_zebra[:, :, i].flatten() for i in range(3)]))\n",
        "print(\"Full zebra image\")\n",
        "print(M_cov)\n",
        "\n",
        "M_cov = np.cov(np.vstack([rect_zebra[:, :, i].flatten() for i in range(3)]))\n",
        "print(\"Rectangle zebra\")\n",
        "print(M_cov)\n",
        "\n",
        "M_cov = np.cov(np.vstack([rect_background[:, :, i].flatten() for i in range(3)]))\n",
        "print(\"Rectangle background\")\n",
        "print(M_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8YAfUvJeALx"
      },
      "source": [
        "Q14: Display the histogram for the R, G and B channels for the \"rect_zebra\" image. Comment on the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_p_ddriRMTq"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A14: It is fairly obvious that for each color, the histograms are very similar. We expected this result since the colors are mainly black and white which are an even intensity mix of the three colors. Moreover, we see a peak in the low intensities, which would correspond to the black parts of the image, as well as a plateau in the high intensity which would correspond to the white parts. The white part is not a peak because it is much more subject to the shade and thus a bigger span of intensities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OuZg14rbeALx",
        "outputId": "ff2a31f4-74ad-407b-b57c-adaa7b05acc2"
      },
      "outputs": [],
      "source": [
        "# Allows you to change the display size of plt.show\n",
        "plt.rcParams[\"figure.figsize\"] = [11, 11]\n",
        "\n",
        "nomchan = [\"red\", \"green\", \"blue\"]\n",
        "for chan in range(3):\n",
        "    plt.figure()\n",
        "    plt.hist(rect_zebra[:, :, chan].flatten(), 100)\n",
        "    plt.title(\"Histogram of the zebra class for the channel \" + nomchan[chan])\n",
        "    plt.show()\n",
        "\n",
        "for chan in range(3):\n",
        "    plt.figure()\n",
        "    plt.hist(rect_background[:, :, chan].flatten(), 100)\n",
        "    plt.title(\"Histogram of the background class for the channel \" + nomchan[chan])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDjO5aL5eALy"
      },
      "source": [
        "Q15: Propose an algorithmic method to identify the two classes of the image \"rect_zebra\". Use a sklearn implementation of this algorithm to identify the mean vectors ($m_R$,$m_G$,$m_B$) for two classes of the \"rect_zebra\" image and two classes of the \"rect_background\" image.\n",
        "\n",
        "*The following line of code can be used to transform the image into a suitable form.*\n",
        "\n",
        "X = np.vstack([rect_zebra[:,:,i].flatten() for i in range(3)]).transpose()\n",
        "\n",
        "Comment on the average vectors obtained. They can be displayed as an image using the code provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5XoOjc1531V"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A15: It is interesting to use the K-means algorithm because for each class, the variances of each color are pretty close which satisfies the hypothesis of this algorithm that the clusters are spherical. Using K=2 for rect_zebra makes sense since we observed two different stacks in the histograms.\n",
        "\n",
        "The vectors obtained make sense since we obtain a dark color, almost black, that corresponds to the black stripes which caused the big peak in the histogram. The second vector is a pretty dark shade of white which we expected since there are many different shades in the rectangle. Also, the high intensities in the histogram showed a plateau that wasn't much higher than the other intensities which means that the mean was pulled toward darker intensities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyOzSp13eALy",
        "outputId": "e413fea0-9e4f-4c40-8196-8be8e3260d83"
      },
      "outputs": [],
      "source": [
        "# Computation of class parameters in a semi-automatic way\n",
        "\n",
        "# Use a number of classes =2 for the zebra part (complete n_clusters=?)\n",
        "X = np.vstack([rect_zebra[:, :, i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_zebra = KMeans(n_clusters=2, random_state=0).fit(X)\n",
        "mean_vectors_zebra = kmeans_zebra.cluster_centers_\n",
        "\n",
        "# Use a number of classes =2 for the background part\n",
        "X = np.vstack([rect_background[:, :, i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_background = KMeans(n_clusters=2, random_state=0).fit(X)\n",
        "mean_vectors_background = kmeans_background.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "Yxiv4ZmUeALz",
        "outputId": "13253e5c-805b-4990-d9a9-b3de35d97d66"
      },
      "outputs": [],
      "source": [
        "# Display of the class centers found as an image\n",
        "image_mean_vectors = np.zeros((200, 200, 3), np.uint8)\n",
        "\n",
        "for i in range(3):\n",
        "    image_mean_vectors[0:99, 0:99, i] = mean_vectors_zebra[0, i]\n",
        "    image_mean_vectors[0:99, 100:199, i] = mean_vectors_zebra[1, i]\n",
        "    image_mean_vectors[100:199, 0:99, i] = mean_vectors_background[0, i]\n",
        "    image_mean_vectors[100:199, 100:199, i] = mean_vectors_background[1, i]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image_mean_vectors, vmax=255)\n",
        "plt.title(\"Top: zebra classes, bottom: background classes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m7NevXDeALz"
      },
      "source": [
        "Q16: Display separately two neg-log-likelihood images (the neg-log-likelihood was used as a data attachment in the previous example) for the two zebra classes.\n",
        "Build a neg-log-likelihood image corresponding to the minimum of the two neg-log-likelihoods of the zebra classes. Similarly for the background class.\n",
        "\n",
        "Display them and comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMXjRkeH0xVp"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A16: For both the background and zebra classes, we can see that all of the pixels classified by the first sub-class are correct but it also misses many of its class's pixels. However, the second sub-class classifies most of the missing pixel but it also takes many pixels that are wrongly classified. In the combined images of both sub-classes, we can see some overlap even though the aimed classes are fully represented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZhZk35freALz",
        "outputId": "ee64ac28-9341-4284-d2cf-06a90abf3fc4"
      },
      "outputs": [],
      "source": [
        "# Calculation of the neg-log-likelihood of the zebra class\n",
        "neg_log_likelihood_zebra_0 = sum(\n",
        "    (I_zebra[:, :, i] - mean_vectors_zebra[0, i]) ** 2 for i in range(3)\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_0, cmap=\"gray\", vmax=600)\n",
        "plt.title(\"neg_log_likelihood_zebra_0\")\n",
        "plt.show()\n",
        "\n",
        "neg_log_likelihood_zebra_1 = sum(\n",
        "    (I_zebra[:, :, i] - mean_vectors_zebra[1, i]) ** 2 for i in range(3)\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_1, cmap=\"gray\", vmax=5000)\n",
        "plt.title(\"neg_log_likelihood_zebra_1\")\n",
        "plt.show()\n",
        "\n",
        "neg_log_likelihood_zebra_combined = np.minimum(\n",
        "    sum((I_zebra[:, :, i] - mean_vectors_zebra[0, i]) ** 2 for i in range(3)),\n",
        "    sum((I_zebra[:, :, i] - mean_vectors_zebra[1, i]) ** 2 for i in range(3)),\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_combined, cmap=\"gray\", vmax=5000)\n",
        "plt.title(\"neg_log_likelihood_zebra_combined\")\n",
        "plt.show()\n",
        "\n",
        "# TO BE COMPLETED\n",
        "# calculate the neg-log-likelihood of the background\n",
        "# call the output neg_log_likelihood_background_combined\n",
        "neg_log_likelihood_background_0 = sum(\n",
        "    (I_zebra[:, :, i] - mean_vectors_background[0, i]) ** 2 for i in range(3)\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_background_0, cmap=\"gray\", vmax=600)\n",
        "plt.title(\"neg_log_likelihood_background_0\")\n",
        "plt.show()\n",
        "\n",
        "neg_log_likelihood_background_1 = sum(\n",
        "    (I_zebra[:, :, i] - mean_vectors_background[1, i]) ** 2 for i in range(3)\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_background_1, cmap=\"gray\", vmax=5000)\n",
        "plt.title(\"neg_log_likelihood_background_1\")\n",
        "plt.show()\n",
        "\n",
        "neg_log_likelihood_background_combined = np.minimum(\n",
        "    sum((I_zebra[:, :, i] - mean_vectors_background[0, i]) ** 2 for i in range(3)),\n",
        "    sum((I_zebra[:, :, i] - mean_vectors_background[1, i]) ** 2 for i in range(3)),\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_background_combined, cmap=\"gray\", vmax=5000)\n",
        "plt.title(\"neg_log_likelihood_background_combined\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDrVWWxQeALz"
      },
      "source": [
        "Q17: From these combined data attachment images (one for the background and one for the zebra), set up a graph-cut segmentation of the image with the $\\beta$ of your choice. Comment the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81C1KbDr2XoW"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A17: The result is pretty good but there are some major mistakes such as the zebra's behind and belly. We also see that it struggles to follow the contour around its neck and mane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ECAh3_eCeALz",
        "outputId": "b7642ebb-16a6-4334-9e52-e980b4316a37"
      },
      "outputs": [],
      "source": [
        "beta = 100000  # Optimal beta value to be determined\n",
        "\n",
        "## Binary graph cut\n",
        "\n",
        "# Create the graph.\n",
        "\n",
        "# Graph instantiation\n",
        "g = maxflow.Graph[float]()\n",
        "# Add the nodes. nodeids has the identifiers of the nodes in the grid.\n",
        "nodeids = g.add_grid_nodes(\n",
        "    I_zebra.shape[0:2]\n",
        ")  # Create a grid with a non-terminal node for each pixel in the image\n",
        "\n",
        "# Add non-terminal edges with the same capacity.\n",
        "g.add_grid_edges(\n",
        "    nodeids, beta\n",
        ")  # Addition of a beta weight edge between each adjacent node according to the 4-connexity\n",
        "\n",
        "# Add the terminal edges.\n",
        "# TO BE COMPLETED\n",
        "g.add_grid_tedges(\n",
        "    nodeids, neg_log_likelihood_zebra_combined, neg_log_likelihood_background_combined\n",
        ")\n",
        "\n",
        "# Find the maximum flow.\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "\n",
        "# Get the segments of the nodes in the grid.\n",
        "sgm = g.get_grid_segments(nodeids)\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im_bin)\n",
        "plt.title(\"Result of the segmentation\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(display_segmentation_borders(I_zebra, im_bin))\n",
        "plt.title(\"Red segmentation contours\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9x_xqQheAL0"
      },
      "source": [
        "Q18: From the obtained segmentation, determine the mean vectors for 5 classes for the background and 5 classes for the zebra. Use these lists of mean vectors to construct new neg-log-likelihood combination images. Comment on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldB8fTnL3fqw"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A18: This time, we see that there is much less overlap between the classes. Some stripes of the zebra are classified as background but they are also classified as zebra so we can hope to segment them as zebra with a good tuning of beta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwje0HN6eAL0",
        "outputId": "555ac6c6-5606-44af-db5b-3e26b3630e9e"
      },
      "outputs": [],
      "source": [
        "# The computing of this cell can take several minutes.\n",
        "X_1 = np.vstack([I_zebra[im_bin == 1, i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_zebra2 = KMeans(n_clusters=5, random_state=0).fit(X_1)\n",
        "mean_vectors_zebra2 = kmeans_zebra2.cluster_centers_\n",
        "\n",
        "X_2 = np.vstack([I_zebra[im_bin == 0, i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_background2 = KMeans(n_clusters=5, random_state=0).fit(X_2)\n",
        "mean_vectors_background2 = kmeans_background2.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C90SebBkeAL1",
        "outputId": "7c204037-4fb0-4280-d5be-fe7a94084a5f"
      },
      "outputs": [],
      "source": [
        "neg_log_likelihood_zebra_combined_2 = np.amin(\n",
        "    np.dstack(\n",
        "        [\n",
        "            (\n",
        "                sum(\n",
        "                    (I_zebra[:, :, i] - mean_vectors_zebra2[n_cl, i]) ** 2\n",
        "                    for i in range(3)\n",
        "                )\n",
        "            )\n",
        "            for n_cl in range(len(mean_vectors_zebra2))\n",
        "        ]\n",
        "    ),\n",
        "    2,\n",
        ")\n",
        "\n",
        "neg_log_likelihood_background_combined_2 = np.amin(\n",
        "    np.dstack(\n",
        "        [\n",
        "            (\n",
        "                sum(\n",
        "                    (I_zebra[:, :, i] - mean_vectors_background2[n_cl, i]) ** 2\n",
        "                    for i in range(3)\n",
        "                )\n",
        "            )\n",
        "            for n_cl in range(len(mean_vectors_background2))\n",
        "        ]\n",
        "    ),\n",
        "    2,\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_combined_2, cmap=\"gray\", vmax=3000)\n",
        "plt.title(\"neg_log_likelihood_zebra_combined_2\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_background_combined_2, cmap=\"gray\", vmax=1000)\n",
        "plt.title(\"neg_log_likelihood_background_combined_2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyREjjNVeAL2"
      },
      "source": [
        "\n",
        "Q19: From these neg-log-likelihood images, segment the image by graph-cut using a new value of $\\beta$ that gives you the best result. Comment on the result and the new value of $\\beta$ that allowed you to obtain it. What about the new 5-class data attachment compared to the previous one?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5DbiDd75afC"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A19: The result is almost perfect. The only mistake is due to a grey rock behind the zebra's ear that is hard to differentiate from the animal, even visually.\n",
        "\n",
        "We note that the value of beta is a lot smaller. This is due to the fact that we have 5 subclasses which implies that there is going to be more limits between classes and thus more penalization.\n",
        "\n",
        "In the end we find that the new 5-class data attachment strategy modelizes more faithfully the data than the 2-class one. It allowed to have more precise sub-classes and thus reduce the overlap between the two classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zx8dBjfjeAL2",
        "outputId": "cca086a9-6a12-4c85-cb7b-8d47849af48a"
      },
      "outputs": [],
      "source": [
        "# Optimal beta value to be determined\n",
        "beta = 10000\n",
        "\n",
        "# Graph instantiation\n",
        "g = maxflow.Graph[float]()\n",
        "\n",
        "# Add the nodes. nodeids has the identifiers of the nodes in the grid.\n",
        "nodeids = g.add_grid_nodes(I_zebra.shape[0:2])\n",
        "\n",
        "# Add non-terminal edges with the same capacity.\n",
        "g.add_grid_edges(nodeids, beta)\n",
        "\n",
        "# Add the terminal edges.\n",
        "g.add_grid_tedges(\n",
        "    nodeids,\n",
        "    neg_log_likelihood_background_combined_2,\n",
        "    neg_log_likelihood_zebra_combined_2,\n",
        ")\n",
        "\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "# Get the segments of the nodes in the grid.\n",
        "sgm = g.get_grid_segments(\n",
        "    nodeids\n",
        ")  # Returns 1 if the pixel is on the drain side after calculation of the min cut, 0 if it is on the source side\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "affiche(im_bin, titre=\"Result for beta = \" + str(beta))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im_bin)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(display_segmentation_borders(I_zebra, im_bin))\n",
        "plt.title(\"Red segmentation contours\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
